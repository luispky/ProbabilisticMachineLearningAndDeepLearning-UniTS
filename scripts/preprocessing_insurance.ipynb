{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "data = pd.read_csv(cwd + '/../datasets/train.csv')\n",
    "\n",
    "# remove spaces in column names\n",
    "data.columns = data.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381109 entries, 0 to 381108\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    381109 non-null  int64  \n",
      " 1   Gender                381109 non-null  object \n",
      " 2   Age                   381109 non-null  int64  \n",
      " 3   Driving_License       381109 non-null  int64  \n",
      " 4   Region_Code           381109 non-null  float64\n",
      " 5   Previously_Insured    381109 non-null  int64  \n",
      " 6   Vehicle_Age           381109 non-null  object \n",
      " 7   Vehicle_Damage        381109 non-null  object \n",
      " 8   Annual_Premium        381109 non-null  float64\n",
      " 9   Policy_Sales_Channel  381109 non-null  float64\n",
      " 10  Vintage               381109 non-null  int64  \n",
      " 11  Response              381109 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(3)\n",
      "memory usage: 34.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# summary of data types and missing values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values of the columns Gender and Vehicle_Damage to binary values (0, 1)\n",
    "\n",
    "data = pd.get_dummies(data, columns=['Gender', 'Vehicle_Damage', 'Driving_License', 'Previously_Insured'], drop_first=True)\n",
    "\n",
    "# encode the values of the column Vehicle_Age to numerical values\n",
    "le = LabelEncoder()\n",
    "data['Vehicle_Age'] = le.fit_transform(data['Vehicle_Age'])\n",
    "\n",
    "# drop id and Vintage columns\n",
    "data = data.drop(['id', 'Vintage'], axis=1)\n",
    "\n",
    "# transfrom Annual_Premium to log scale\n",
    "data['Annual_Premium'] = np.log(data['Annual_Premium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381109 entries, 0 to 381108\n",
      "Data columns (total 10 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   Age                             381109 non-null  int64  \n",
      " 1   Region_Code                     381109 non-null  float64\n",
      " 2   Vehicle_Age                     381109 non-null  int64  \n",
      " 3   Annual_Premium                  381109 non-null  float64\n",
      " 4   Policy_Sales_Channel            381109 non-null  float64\n",
      " 5   Response                        381109 non-null  int64  \n",
      " 6   Gender_Male                     381109 non-null  bool   \n",
      " 7   Vehicle_Damage_Yes              381109 non-null  bool   \n",
      " 8   Driving_License_1               381109 non-null  bool   \n",
      " 9   Previously_Insured_1            381109 non-null  bool   \n",
      "dtypes: bool(4), float64(3), int64(3)\n",
      "memory usage: 18.9 MB\n"
     ]
    }
   ],
   "source": [
    "# summary of data types and missing values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 4 values of Policy_Sales_Channel whose proportion is greater than 0.05 and replace the rest with 0\n",
    "data['Policy_Sales_Channel'] = data['Policy_Sales_Channel'].where(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdata['Policy_Sales_Channel'].map(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdata['Policy_Sales_Channel'].value_counts(normalize=True)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t).ge(0.05), 0\n",
    "                              \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "# select the top 4 values of Region_Code whose proportion is greater than 0.05 and replace the rest with 0\n",
    "data['Region_Code'] = data['Region_Code'].where(data['Region_Code'].map(data['Region_Code'].value_counts(normalize=True)).ge(0.04), 0)\n",
    "\n",
    "# convert the columns Policy_Sales_Channel and Region_Code to integer\n",
    "data['Policy_Sales_Channel'] = data['Policy_Sales_Channel'].astype(int)\n",
    "data['Region_Code'] = data['Region_Code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy_Sales_Channel\n",
      "152    0.353663\n",
      "26     0.209127\n",
      "124    0.194157\n",
      "0      0.185907\n",
      "160    0.057146\n",
      "Name: proportion, dtype: float64\n",
      "Region_Code\n",
      "0     0.532144\n",
      "28    0.279225\n",
      "8     0.088891\n",
      "46    0.051820\n",
      "41    0.047921\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data['Policy_Sales_Channel'].value_counts(normalize=True))\n",
    "\n",
    "print(data['Region_Code'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply one-hot encoding to the columns Policy_Sales_Channel and Region_Code\n",
    "data = pd.get_dummies(data, columns=['Policy_Sales_Channel', 'Region_Code'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381109 entries, 0 to 381108\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   Age                             381109 non-null  int64  \n",
      " 1   Vehicle_Age                     381109 non-null  int64  \n",
      " 2   Annual_Premium                  381109 non-null  float64\n",
      " 3   Response                        381109 non-null  int64  \n",
      " 4   Gender_Male                     381109 non-null  bool   \n",
      " 5   Vehicle_Damage_Yes              381109 non-null  bool   \n",
      " 6   Driving_License_1               381109 non-null  bool   \n",
      " 7   Previously_Insured_1            381109 non-null  bool   \n",
      " 8   Policy_Sales_Channel_26         381109 non-null  bool   \n",
      " 9   Policy_Sales_Channel_124        381109 non-null  bool   \n",
      " 10  Policy_Sales_Channel_152        381109 non-null  bool   \n",
      " 11  Policy_Sales_Channel_160        381109 non-null  bool   \n",
      " 12  Region_Code_8                   381109 non-null  bool   \n",
      " 13  Region_Code_28                  381109 non-null  bool   \n",
      " 14  Region_Code_41                  381109 non-null  bool   \n",
      " 15  Region_Code_46                  381109 non-null  bool   \n",
      "dtypes: bool(12), float64(1), int64(3)\n",
      "memory usage: 16.0 MB\n"
     ]
    }
   ],
   "source": [
    "# summary of data types and missing values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n",
      "0    0.877437\n",
      "1    0.122563\n",
      "Name: proportion, dtype: float64\n",
      "Dataset size: (381109, 16)\n"
     ]
    }
   ],
   "source": [
    "# proportion of the values of the Response column\n",
    "print(data['Response'].value_counts(normalize=True))\n",
    "print(f'Dataset size: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our goal is to transform the instances classified as 1 in the Response column to instances classified as 0\n",
    "# Therefore, instead of using all the rows we will use a subset of the data which still is a lot and might be enough\n",
    "# for the diffusion model that we will use for the transformation.\n",
    "# ! This could change later\n",
    "# * We want to first build a classifier and then use the generative model for the transformation\n",
    "# For the classifier we increase the proportion of the instances classified as 1 in the Response column \n",
    "# by sampling according to the proportions of the classes\n",
    "\n",
    "# Separate the dataframe into two based on the binary column\n",
    "data_0 = data[data['Response'] == 0]\n",
    "data_1 = data[data['Response'] == 1]\n",
    "\n",
    "# Define your proportions\n",
    "prop_0 = 0.8  # Proportion of samples for class 0\n",
    "prop_1 = 0.2  # Proportion of samples for class 1\n",
    "\n",
    "# Calculate the number of samples for each class\n",
    "n_samples = 100_000  # Total number of samples\n",
    "n_samples_0 = int(n_samples * prop_0)\n",
    "n_samples_1 = int(n_samples * prop_1)\n",
    "\n",
    "# Sample separately\n",
    "sampled_data_0 = data_0.sample(n=n_samples_0, random_state=1)\n",
    "sampled_data_1 = data_1.sample(n=n_samples_1, random_state=1)\n",
    "\n",
    "# Concatenate the results\n",
    "sampled_data = pd.concat([sampled_data_0, sampled_data_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response_1\n",
      "False    0.8\n",
      "True     0.2\n",
      "Name: proportion, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100000 entries, 149144 to 326208\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   Age                             100000 non-null  int64  \n",
      " 1   Vehicle_Age                     100000 non-null  int64  \n",
      " 2   Annual_Premium                  100000 non-null  float64\n",
      " 3   Gender_Male                     100000 non-null  bool   \n",
      " 4   Vehicle_Damage_Yes              100000 non-null  bool   \n",
      " 5   Driving_License_1               100000 non-null  bool   \n",
      " 6   Previously_Insured_1            100000 non-null  bool   \n",
      " 7   Policy_Sales_Channel_26         100000 non-null  bool   \n",
      " 8   Policy_Sales_Channel_124        100000 non-null  bool   \n",
      " 9   Policy_Sales_Channel_152        100000 non-null  bool   \n",
      " 10  Policy_Sales_Channel_160        100000 non-null  bool   \n",
      " 11  Region_Code_8                   100000 non-null  bool   \n",
      " 12  Region_Code_28                  100000 non-null  bool   \n",
      " 13  Region_Code_41                  100000 non-null  bool   \n",
      " 14  Region_Code_46                  100000 non-null  bool   \n",
      " 15  Response_1                      100000 non-null  bool   \n",
      "dtypes: bool(13), float64(1), int64(2)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding of the Response column\n",
    "sampled_data = pd.get_dummies(sampled_data, columns=['Response'], drop_first=True)\n",
    "\n",
    "# proportion of the values of the Response column in the new encoded column\n",
    "print(sampled_data['Response_1'].value_counts(normalize=True))\n",
    "\n",
    "# summary of data types and missing values\n",
    "sampled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as a csv file\n",
    "sampled_data.to_csv(cwd + '/../datasets/sample_data_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's split the sampled data into train and test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = sampled_data.drop('Response_1', axis=1)\n",
    "# y = sampled_data['Response_1']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# # Normalize Age, Vehicle_Age, Annual_Premium columns of the train and test sets\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_train[['Age', 'Vehicle_Age', 'Annual_Premium']] = scaler.fit_transform(X_train[['Age', 'Vehicle_Age', 'Annual_Premium']])\n",
    "# X_test[['Age', 'Vehicle_Age', 'Annual_Premium']] = scaler.transform(X_test[['Age', 'Vehicle_Age', 'Annual_Premium']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
