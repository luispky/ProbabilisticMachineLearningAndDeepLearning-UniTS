
Training...











Epoch: 53 | Loss: 0.0227:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 53/64 [00:23<00:04,  2.23it/s]
Traceback (most recent call last):
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/scripts/run_diffusion.py", line 233, in <module>
    main_sum_categorical_data()
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/scripts/run_diffusion.py", line 183, in main_sum_categorical_data
    train_losses = diffusion.train(dataloader, ema)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/src/denoising_diffusion_pm.py", line 123, in train
    optimizer.step()
  File "/home/l11/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/l11/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/l11/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/home/l11/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/home/l11/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/adamw.py", line 517, in _multi_tensor_adamw
    grouped_tensors = Optimizer._group_tensors_by_device_and_dtype([
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/l11/miniconda3/envs/DL/lib/python3.12/site-packages/torch/optim/optimizer.py", line 402, in _group_tensors_by_device_and_dtype
    @staticmethod
KeyboardInterrupt