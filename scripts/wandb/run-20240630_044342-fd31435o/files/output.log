
Training...













Epoch: 63 | Loss: 0.0180:  98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 63/64 [00:27<00:00,  2.37it/s]
Training Finished
Sampling...
Sampling Finished
Min value: 0.0
Epoch: 64 | Loss: 0.0180: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:27<00:00,  2.29it/s]
128it [00:00, 1028.08it/s]
Traceback (most recent call last):
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/scripts/run_diffusion.py", line 277, in <module>
    main_sum_categorical_data()
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/scripts/run_diffusion.py", line 207, in main_sum_categorical_data
    normalized_data = prob_instance.normalize(samples)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/src/utils.py", line 573, in normalize
    assert np.all(s > 0), f'Zero sum: {s}'
           ^^^^^^^^^^^^^
AssertionError: Zero sum: [[1.         1.         1.11428311 ... 1.49326089 1.49326089 1.49326089]
 [1.08541674 1.08541674 0.94761869 ... 0.93245079 0.93245079 0.93245079]
 [1.         1.         0.9595698  ... 1.10641783 1.10641783 1.10641783]
 ...
 [1.1075317  1.1075317  0.99794745 ... 0.88917598 0.88917598 0.88917598]
 [0.92258041 0.92258041 1.02014107 ... 1.21308481 1.21308481 1.21308481]
 [1.00459564 1.00459564 0.97111461 ... 0.89748265 0.89748265 0.89748265]]