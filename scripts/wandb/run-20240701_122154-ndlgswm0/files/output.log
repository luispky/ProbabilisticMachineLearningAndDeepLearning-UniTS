
Training...

















Epoch: 61 | Loss: 0.0179:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 61/64 [00:34<00:01,  1.85it/s]
Training Finished
Epoch: 64 | Loss: 0.0180: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:36<00:00,  1.76it/s]
0it [00:00, ?it/s]
Sampling Finished
Min value: 0.0
128it [00:02, 51.55it/s]
Traceback (most recent call last):
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/scripts/run_diffusion.py", line 274, in <module>
    main_sum_categorical_data()
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/scripts/run_diffusion.py", line 208, in main_sum_categorical_data
    normalized_data = prob_instance.normalize(samples)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/l11/Documents/ProbabilisticMachineLearningProject/src/utils.py", line 551, in normalize
    assert np.all(s > 0), f'Zero sum: {s}'
           ^^^^^^^^^^^^^
AssertionError: Zero sum: [[0.60381965 0.60381965 0.95880254 ... 1.0472527  1.0472527  1.0472527 ]
 [1.29138899 1.29138899 1.0824444  ... 1.1604305  1.1604305  1.1604305 ]
 [0.20096052 0.20096052 1.05118495 ... 1.58366735 1.58366735 1.58366735]
 ...
 [0.54089099 0.54089099 0.95365924 ... 1.33478517 1.33478517 1.33478517]
 [0.6942606  0.6942606  0.88941101 ... 1.24712867 1.24712867 1.24712867]
 [1.51813072 1.51813072 1.19810483 ... 1.34090394 1.34090394 1.34090394]]